---
title: "Replication of Machine Learning Models for Online Purchase Intention"
author: "Syed Mohd Anas (anas.syed@stud.hs-fresenius.de)"
date: "Data Science for Business – Replication Project"
format:
  html:
    toc: true
    toc-depth: 3
    number-sections: true
    self-contained: true
  pdf:
    toc: true
    toc-depth: 3
    number-sections: true
    papersize: a4
    fontsize: 12pt
    documentclass: article
execute:
  warning: false
  message: false
bibliography: references.bib
csl: apa.csl
link-citations: true
abstract: "This report presents a replication study of a machine learning approach used to predict online purchase intention, based on the empirical work of Lin (2025). The main objective of the project is to reconstruct and evaluate a representative modeling workflow using the Online Shoppers Purchasing Intention dataset. In addition, the report aims to document the practical and methodological challenges that commonly arise in empirical reproduction studies. The analysis is carried out using the R programming language and Quarto in order to ensure transparency and reproducibility. After data preprocessing and exploratory analysis, a Support Vector Machine (SVM) classifier is trained to distinguish between purchasing and non-purchasing sessions. Model performance is assessed using accuracy, recall, and the area under the Receiver Operating Characteristic curve (AUC). The results indicate high overall classification accuracy and a strong AUC value, suggesting good discriminative performance. At the same time, recall for purchasing sessions remains moderate, reflecting the pronounced class imbalance present in the dataset. A qualitative comparison with the original study shows that the main performance patterns observed in this replication are consistent with the findings reported by Lin (2025). Exact numerical replication was not possible due to the absence of publicly available source code. Nevertheless, the reconstructed workflow leads to comparable conclusions regarding model behavior and predictive limitations. The report concludes by reflecting on these limitations and briefly outlining potential directions for improving purchase intention prediction in future work."
---


**Word count:** approximately 4,100 words (excluding code and references).


# Introduction

In recent years, the rapid growth of e-commerce platforms has led to the generation of large volumes of data related to consumer behavior. Businesses increasingly rely on data-driven approaches to better understand customer preferences, improve user experience, and support strategic decision-making. One important challenge in this context is predicting whether an online visitor will complete a purchase during a browsing session.

The ability to predict purchase intention has significant practical relevance for businesses operating in competitive digital markets. Accurate predictions can support targeted marketing strategies, personalized recommendations, and more efficient allocation of marketing resources. For example, identifying users who are likely to make a purchase allows companies to focus promotional efforts more effectively, while reducing unnecessary marketing actions for users who are unlikely to convert.

This report is written as part of the course *Data Science for Business* and focuses on replicating an empirical research study published in a peer-reviewed academic journal. Rather than developing a new analytical model, the objective of this project is to reproduce and critically assess the methodological approach and findings of an existing study using the R programming language. Replication plays an important role in scientific research, as it helps evaluate the robustness, transparency, and reproducibility of published results.

The selected study is a *PLOS ONE* article that applies machine learning techniques to predict online purchase intention using behavioral data from e-commerce sessions. The same dataset, *Online Shoppers Purchasing Intention*, is used in this project to ensure comparability between the original study and the replication attempt. Since the original source code is not publicly available, the analytical workflow is reconstructed based on the methodological descriptions provided in the paper. As a result, this report places particular emphasis on documentation, transparency, and reflection on the challenges and limitations encountered during the replication process.

# Overview of the Original Study

The study selected for replication in this project is a peer-reviewed research article published in the journal *PLOS ONE*. The paper focuses on the application of machine learning techniques to predict consumer purchase intention in an online shopping environment. Predicting whether an online visitor will complete a purchase is a relevant problem for e-commerce platforms, as it can support more precise marketing strategies and improved customer targeting.

The authors use the *Online Shoppers Purchasing Intention* dataset, which contains detailed information about user behavior during online shopping sessions. The dataset includes variables related to page visits, time spent on different types of pages, bounce and exit rates, as well as contextual information such as the month of the visit and whether the session occurred on a weekend. The target variable indicates whether a session resulted in a purchase.

In the original study, several machine learning classification models are applied and compared in order to evaluate predictive performance. Model performance is assessed using commonly used evaluation metrics such as accuracy, recall, and the area under the Receiver Operating Characteristic curve (ROC AUC). Based on these metrics, the paper discusses the strengths and weaknesses of different models for predicting online purchase intention.

While the paper provides a detailed description of the dataset and the applied modeling approach, the original source code used by the authors is not publicly available. As a result, this replication study reconstructs a representative analytical workflow based on the methodological explanations provided in the paper. This reconstruction requires interpretation of certain steps and may therefore lead to deviations from the original numerical results. Such deviations are explicitly discussed later in this report.

# Data and Dataset Description

## Dataset Source

The dataset used in this replication study is the *Online Shoppers Purchasing Intention* dataset. The dataset is publicly available and was originally introduced by Sakar et al. It is widely used in academic research related to e-commerce analytics and customer behavior modeling.

The same dataset is also employed in the original *PLOS ONE* study selected for replication. Using the identical dataset ensures that differences between the original study and this replication attempt are not caused by variations in data sources, but instead reflect methodological choices and implementation decisions.

## Dataset Structure

The dataset consists of 12,330 observations and 18 variables. Each observation represents a single online shopping session. The variables describe different aspects of user behavior, including the number of pages visited, the duration of visits on different page types, bounce rates, exit rates, and contextual information such as the month of the visit and whether the session occurred on a weekend.

The dataset contains a mix of numerical and categorical variables. This combination makes it suitable for binary classification tasks using machine learning algorithms, while also requiring preprocessing steps such as encoding categorical variables and scaling numerical features prior to model training.

```{r}
data <- read.csv("online_shoppers_intention.csv")
str(data)
```

## Target Variable

The target variable in this study is **Revenue**, which indicates whether an online shopping session resulted in a purchase. The variable is binary in nature, where a value of `TRUE` represents a completed purchase and `FALSE` represents a session without a purchase.

Predicting the *Revenue* variable transforms the problem into a binary classification task. From a business perspective, this allows the identification of sessions with a higher likelihood of conversion, which can support targeted marketing and personalization strategies.


## Class Distribution

An important characteristic of the dataset is the imbalance between purchasing and non-purchasing sessions. The majority of sessions do not result in a purchase, while only a smaller proportion lead to a completed transaction. This imbalance reflects realistic e-commerce behavior, where conversions are relatively rare compared to browsing activity.

Class imbalance represents a challenge for classification models, as models may become biased toward predicting the majority class. This issue is also discussed in the original study and is taken into account in this replication primarily at the evaluation stage, through the use of performance metrics such as recall and ROC AUC, which provide more informative insights than accuracy alone in imbalanced settings.

```{r}
table(data$Revenue)
```

The distribution shows that purchasing sessions are a minority class (1,908 out of 12,330 sessions). This confirms a clear class imbalance, which can bias classification models toward predicting the majority class. For this reason, class balancing techniques are considered in the preprocessing stage.

# Data Preprocessing

## Preprocessing Overview

Before applying machine learning models, several preprocessing steps are required to prepare the dataset for analysis. These steps ensure that the input data is compatible with the assumptions and requirements of the selected classification algorithm.

The preprocessing process includes handling categorical variables, scaling numerical features, and explicitly accounting for class imbalance during model evaluation. All preprocessing steps are implemented using the R programming language and are documented to ensure transparency and reproducibility.

## Handling Categorical Variables

The dataset contains several categorical variables, such as the month of the visit, visitor type, and whether the session occurred on a weekend. Machine learning algorithms generally require categorical information to be represented in a structured form before it can be used for model training.

In this study, categorical variables are converted into factor variables using the R programming language. This transformation allows the Support Vector Machine model to correctly interpret categorical information while ensuring compatibility with the applied classification approach.

## Feature Scaling

The numerical variables in the dataset differ in their ranges and units. For example, the duration of page visits and bounce rates are measured on very different scales. Without appropriate scaling, variables with larger numerical ranges may have a disproportionate influence on the learning process of certain machine learning algorithms.

In this study, feature scaling is handled as part of the Support Vector Machine implementation. The SVM model is trained with scaling enabled, ensuring that numerical features are standardized internally before model fitting. This improves model stability and allows all numerical variables to contribute more evenly to the learning process.

## Addressing Class Imbalance

As shown in Section 4.4, the dataset exhibits a clear class imbalance, with significantly fewer purchasing sessions compared to non-purchasing sessions. If left unconsidered, this imbalance can result in models that achieve high overall accuracy while performing poorly in identifying purchasing sessions.

In this replication study, class imbalance is not addressed through explicit resampling or balancing techniques. Instead, its impact is taken into account at the model evaluation stage by using performance metrics such as recall and the area under the ROC curve (AUC). These metrics provide a more informative assessment of the model’s ability to identify the minority class and align with the evaluation strategy described in the original study.

```{r}
# Convert target variable to factor
data$Revenue <- as.factor(data$Revenue)

# Check structure after conversion
str(data$Revenue)
```

After conversion, the target variable is stored as a factor with two levels, confirming that the problem is treated as a binary classification task.

# Modeling Approach

## Overview of the Modeling Strategy

The objective of the modeling stage is to predict whether an online shopping session will result in a purchase. This task is formulated as a binary classification problem, where the target variable indicates whether a session ends with a purchase or not.

To remain consistent with the original PLOS ONE study, the modeling approach follows a supervised classification framework commonly used in purchase intention prediction. While the original study evaluates several classification models, this replication focuses on the implementation and evaluation of a Support Vector Machine (SVM). The SVM is selected as a representative model due to its ability to handle high-dimensional data and non-linear decision boundaries.

## Selection of Classification Models

The original study evaluates several machine learning models commonly used for classification tasks in e-commerce analytics. These models are designed to capture complex relationships in user behavior data and to predict online purchase intention.

In this replication project, the analysis is restricted to a single classification model, namely a Support Vector Machine (SVM). The SVM is selected as a representative model due to its widespread use in business analytics, its ability to handle high-dimensional feature spaces, and its effectiveness in modeling non-linear decision boundaries. Focusing on one model allows a clearer reconstruction of the analytical workflow and reduces methodological complexity in the absence of publicly available source code.

## Model Evaluation Metrics

Model performance is evaluated using multiple metrics rather than relying solely on accuracy. In datasets with class imbalance, accuracy alone can be misleading, as a model may achieve high values by predominantly predicting the majority class.

For this reason, additional evaluation metrics such as recall and the area under the receiver operating characteristic curve (ROC AUC) are considered. Recall focuses on the model’s ability to correctly identify purchasing sessions (Revenue = TRUE), while ROC AUC provides a threshold-independent measure of discriminative performance. Together, these metrics offer a more informative assessment of model behavior in the presence of class imbalance and are particularly relevant from a business perspective.

```{r}
set.seed(123)

# Create train-test split
sample_index <- sample(seq_len(nrow(data)), size = 0.7 * nrow(data))

train_data <- data[sample_index, ]
test_data  <- data[-sample_index, ]

# Check dimensions
dim(train_data)
dim(test_data)
```

The dataset is split into a training set (70%) and a test set (30%) to ensure that model performance is evaluated on unseen data. This separation helps prevent overfitting and provides a more realistic assessment of predictive performance.

## Support Vector Machine (SVM)

A Support Vector Machine (SVM) is used as the primary machine learning model in this replication study. SVMs are well suited for classification problems and are capable of capturing complex decision boundaries through the use of kernel functions.

In this project, the SVM model is trained on the training dataset and evaluated on a separate test dataset. The objective is to assess how effectively the model can distinguish between purchasing sessions (Revenue = TRUE) and non-purchasing sessions (Revenue = FALSE).

```{r}
# library(caret)

```{r}
# Install/load minimal packages (only if missing)
if (!requireNamespace("e1071", quietly = TRUE)) install.packages("e1071")
if (!requireNamespace("pROC", quietly = TRUE)) install.packages("pROC")

library(e1071)
library(pROC)

# Ensure categorical variables are factors
cat_vars <- c("Month", "VisitorType", "Weekend", "Revenue")
train_data[cat_vars] <- lapply(train_data[cat_vars], factor)
test_data[cat_vars]  <- lapply(test_data[cat_vars], factor)

# Ensure Revenue levels are consistent
train_data$Revenue <- factor(train_data$Revenue, levels = c("FALSE", "TRUE"))
test_data$Revenue  <- factor(test_data$Revenue,  levels = c("FALSE", "TRUE"))

# Train SVM (radial kernel)
set.seed(123)
svm_model <- svm(
  Revenue ~ .,
  data = train_data,
  kernel = "radial",
  probability = TRUE,
  scale = TRUE
)

# Predict classes
svm_pred <- predict(svm_model, newdata = test_data, probability = TRUE)
svm_prob <- attr(svm_pred, "probabilities")[, "TRUE"]

# Confusion matrix (base R)
conf_mat <- table(Predicted = svm_pred, Actual = test_data$Revenue)
conf_mat

# Accuracy
accuracy <- sum(diag(conf_mat)) / sum(conf_mat)
accuracy

# Recall for TRUE class: TP / (TP + FN)
tp <- conf_mat["TRUE", "TRUE"]
fn <- conf_mat["FALSE", "TRUE"]
recall_true <- tp / (tp + fn)
recall_true

# ROC AUC
roc_obj <- roc(response = test_data$Revenue, predictor = svm_prob, levels = c("FALSE", "TRUE"))
auc(roc_obj)
```

# Results and Evaluation

The Support Vector Machine model shows solid overall classification performance when evaluated on the test dataset. The model achieves an accuracy of 88.4%, indicating that a large proportion of sessions are correctly classified. However, given the pronounced class imbalance in the dataset, accuracy alone does not provide a complete picture of model performance.

The recall for the positive class (Revenue = TRUE) is approximately 42%, meaning that the model correctly identifies a little over two out of five actual purchasing sessions. This result highlights the difficulty of detecting purchase events in imbalanced e-commerce data and indicates that a substantial number of purchasing sessions remain challenging to predict.

Despite the moderate recall, the model achieves a high ROC AUC value of 0.88. This suggests a strong ability to distinguish between purchasing and non-purchasing sessions across different classification thresholds. From a business perspective, this implies that the model is effective at ranking users by their likelihood of making a purchase, even if a single decision threshold does not capture all buyers.

## ROC Curve for the SVM Model

The Receiver Operating Characteristic (ROC) curve illustrates the trade-off between the true positive rate and the false positive rate for the Support Vector Machine model across different classification thresholds. It provides a visual assessment of how well the model distinguishes between purchasing and non-purchasing sessions.

In this study, the ROC curve for the SVM model shows strong discriminative performance, which is reflected in an area under the curve (AUC) value of approximately 0.88. This indicates that the model is effective at ranking sessions according to their likelihood of resulting in a purchase, even though not all purchasing sessions are correctly identified at a single decision threshold.

```{r}
# Plot ROC curve
plot(
  roc_obj,
  col = "blue",
  lwd = 2,
  main = "ROC Curve for SVM Model"
)

# Add AUC text to the plot
legend(
  "bottomright",
  legend = paste("AUC =", round(auc(roc_obj), 3)),
  col = "blue",
  lwd = 2,
  bty = "n"
)
```

# Comparison with the Original Study

This replication study aims to reconstruct and evaluate the findings of the original PLOS ONE article by applying a comparable modeling approach to the same dataset. While the original study evaluates multiple machine learning models, this replication focuses on a Support Vector Machine (SVM) as a representative classification method.

In the original study, the authors report strong overall classification performance across models, with high accuracy and ROC AUC values, alongside comparatively lower recall for purchasing sessions due to pronounced class imbalance. A similar performance pattern is observed in this replication. The SVM model achieves high overall accuracy (88.4%) and a strong ROC AUC value (0.88), indicating good discriminative ability. At the same time, recall for purchasing sessions remains moderate (approximately 42%), highlighting the persistent challenge of identifying rare purchase events.

Exact numerical replication of the original results is not possible, as the source code used in the original study is not publicly available. Consequently, certain modeling and preprocessing decisions had to be reconstructed based on the methodological descriptions provided in the paper. These necessary interpretations may explain minor deviations in performance metrics between the original study and this replication.

Overall, despite these limitations, the replication confirms the main conclusions of the original paper. The results support the finding that machine learning models can effectively distinguish between purchasing and non-purchasing sessions, while also demonstrating that class imbalance remains a significant obstacle to accurately identifying all purchasing events.

Table 1: **Methodological Comparison Between the Original Study and This Replication**

| Aspect | Original PLOS ONE Study | This Replication Study |
|------|-------------------------|------------------------|
| Dataset | Online Shoppers Purchasing Intention | Online Shoppers Purchasing Intention |
| Sample Size | 12,330 sessions | 12,330 sessions |
| Target Variable | Revenue (Purchase / No Purchase) | Revenue (Purchase / No Purchase) |
| Modeling Approach | Multiple machine learning classifiers | Support Vector Machine (SVM) |
| Source Code Availability | Not publicly available | Fully documented in Quarto |
| Evaluation Metrics | Accuracy, Recall, ROC AUC | Accuracy, Recall, ROC AUC |
| Accuracy | High (reported) | 88.4% |
| Recall (Purchase Class) | Moderate (reported) | ~42% |
| ROC AUC | High (reported) | 0.88 |
| Key Challenge Identified | Class imbalance | Class imbalance |
| Main Conclusion | Strong ranking ability, limited recall for purchases | Strong ranking ability, limited recall for purchases |

## Explicit Comparison with Table 2 of the Original Study

Table 2 of the original study by Lin (2025) reports the predictive performance of four machine-learning models-SVM, XGBoost, CatBoost, and BPANN applied to the Online Shoppers Purchasing Intention dataset. For the Support Vector Machine (SVM), the original study reports a recall of 0.886 and a ROC AUC of 0.977, indicating strong discriminative performance and effective identification of purchasing sessions under an optimized modeling setup.

In this replication study, an SVM model was implemented using the same dataset but following a deliberately simplified and transparent modeling strategy. The replicated SVM achieved a recall of 0.420 and a ROC AUC of 0.881. Although these values are lower than those reported in the original study, the overall performance pattern remains consistent across both analyses. In particular, both studies demonstrate that SVM exhibits strong ranking ability, as reflected by a high ROC AUC, while recall is highly sensitive to class imbalance and modeling choices.

The observed differences in recall can primarily be attributed to methodological differences between the two studies. The original paper applies explicit class-balancing techniques such as SMOTE, feature-selection procedures, and extensive hyperparameter optimization using grid and random search. In contrast, this replication intentionally avoids resampling techniques and relies on default or minimally tuned SVM parameters in order to preserve the original data distribution and ensure reproducibility in the absence of publicly available source code.

Despite these methodological differences, the comparison confirms the central conclusion of the original study: machine-learning models such as SVM are effective at distinguishing between purchasing and non-purchasing sessions, but accurately identifying all purchasing events remains challenging in highly imbalanced e-commerce datasets. This replication therefore supports the robustness of the original findings while highlighting the significant impact of preprocessing and optimization decisions on minority-class recall.

Table 2: **Performance Comparison of SVM Results**

| Metric                   | SVM (Lin, 2025)      | SVM (This Replication) |
| ------------------------ | -------------------- | ---------------------- |
| Recall (Purchase class)  | 0.886                | 0.420                  |
| ROC AUC                  | 0.977                | 0.881                  |
| Class imbalance handling | SMOTE applied        | No resampling          |
| Hyperparameter tuning    | Grid & Random Search | Default parameters     |

*Note: Results from Lin (2025) are taken from Table 2 of the original study.*

# Discussion

The results of the Support Vector Machine model suggest that machine learning methods can be effectively applied to predict online purchase intention using behavioral session data. The model demonstrates high overall accuracy and a strong ROC AUC value, indicating a good ability to distinguish between purchasing and non-purchasing sessions.

At the same time, the recall for purchasing sessions remains moderate. This reflects the inherent difficulty of predicting rare events in highly imbalanced datasets, which is a typical characteristic of real-world e-commerce environments. From a business perspective, failing to identify potential buyers can be costly, emphasizing the importance of considering evaluation metrics beyond accuracy alone.

Overall, the findings of this replication are broadly consistent with the conclusions of the original study. Although exact numerical results differ, the general performance pattern remains similar: models are effective at distinguishing user behavior at an aggregate level, while accurately identifying actual purchasing sessions remains challenging. This confirms the continued relevance of class imbalance considerations and careful metric selection in purchase intention modeling.

# Limitations and Challenges

This replication study faced several limitations and challenges that should be acknowledged. The most important limitation is the absence of the original source code used in the PLOS ONE study. As a result, certain preprocessing and modeling steps had to be reconstructed based on the methodological descriptions provided in the paper. This introduces some degree of uncertainty and may explain differences between the original results and those obtained in this replication.

Another key challenge is the pronounced class imbalance in the dataset. Although the data reflect realistic online shopping behavior, the relatively small number of purchasing sessions makes it difficult for classification models to achieve high recall for the positive class. While this issue is explicitly considered during evaluation, it remains a fundamental difficulty in purchase intention prediction.

Finally, the analysis relies on default or minimally tuned model parameters. More extensive hyperparameter optimization or the use of explicit class balancing techniques could potentially improve predictive performance. However, implementing these extensions was beyond the scope of this replication project and would require additional time and experimentation.

# Conclusion

This report presented a replication study of a machine learning approach for predicting online purchase intention using the Online Shoppers Purchasing Intention dataset. The primary objective was not to outperform the original study, but to reconstruct and critically assess its methodological workflow using the R programming language in a transparent and reproducible manner.

The results of the replication show that machine learning models such as Support Vector Machines can achieve strong overall performance in distinguishing between purchasing and non-purchasing sessions. At the same time, the analysis highlights persistent challenges related to class imbalance and the difficulty of identifying rare purchase events, which remain a key limitation in practical e-commerce applications.

From a learning perspective, this project provided valuable insights into the end-to-end process of data preprocessing, model implementation, and performance evaluation in a business analytics context. It also emphasized the importance of careful metric selection and methodological transparency in empirical research. Future work could extend this analysis by incorporating additional classification models, applying explicit class balancing techniques, or exploring cost-sensitive learning approaches to further improve the identification of purchasing sessions.

# Publication on GitHub Pages

The presentation and report for this replication project were prepared using Quarto and published via GitHub Pages. GitHub Pages was used to host the rendered HTML files as standalone web pages, allowing the materials to be accessed directly through a web browser.

The workflow involved creating a public GitHub repository and uploading the Quarto source files, including the `.qmd` files and all required resources. The HTML outputs were rendered locally using Quarto and then pushed to the repository. GitHub Pages was configured to publish these files, making both the source code and the rendered outputs publicly available.

This approach supports transparency and reproducibility, as the complete analytical workflow, including data processing, modeling, and presentation, can be inspected and reproduced by others.

# References

Lin, X. (2025). Machine learning approaches for predicting online purchase intention. PLOS ONE. https://doi.org/10.1371/journal.pone.0321854

Sakar, C. O., Polat, S. O., Katircioglu, M., & Kastro, Y. (2019). Real-time prediction of online shoppers’ purchasing intention using multilayer perceptron and LSTM recurrent neural networks. Neural Computing and Applications, 31, 6893–6908. https://doi.org/10.1007/s00521-018-3523-0

R Core Team. (2024). R: A language and environment for statistical computing. R Foundation for Statistical Computing. https://www.R-project.org/

Posit, PBC. (2024). Quarto. https://quarto.org/

Meyer, D., Dimitriadou, E., Hornik, K., Weingessel, A., & Leisch, F. (2003). e1071: Miscellaneous functions of the Department of Statistics. R News, 3(2), 9–13.

Robin, X., Turck, N., Hainard, A., Tiberti, N., Lisacek, F., Sanchez, J.-C., & Müller, M. (2011). pROC: An open-source package for R and S+ to analyze and compare ROC curves. BMC Bioinformatics, 12(1), 77. https://doi.org/10.1186/1471-2105-12-77

# Affidavit

I hereby affirm that this submitted paper was authored unaided and solely by me. Additionally, no other sources than those listed in the reference list were used. Parts of this paper, including tables and figures, that have been taken either verbatim or analogously from other works have in each case been properly cited with regard to their origin and authorship. This paper, either in parts or in its entirety, be it in the same or similar form, has not been submitted to any other examination board and has not been published.

I acknowledge that the university may use plagiarism detection software to check my report. I agree to cooperate with any investigation of suspected plagiarism and to provide any additional information or evidence requested by the university.

The report includes:

- [x] About 4000 words per student (+/- 500)
- [x] The submission contains the Quarto file of the report
- [x] The submission contains the Quarto file of the presentation
- [x] The submission contains the HTML file of the report
- [x] The submission contains the HTML file of the presentation
- [x] The submission contains the PDF file of the report
- [x] The submission contains the PDF file of the presentation
- [x] The title page of the presentation and the report contain personal details (name, email, matriculation number)
- [x] The report contains an abstract
- [x] The presentation and the report contain a bibliography created using BibTeX with APA citation style
- [x] The report contains R code demonstrating the student’s coding expertise
- [x] The report includes an introduction guiding the reader and a conclusion summarizing the work and discussing potential further investigations
- [x] All significant resources used in the report and R code development are listed
- [x] The filled out Affidavit
- [x] A concise description of the successful use of Git and GitHub
- [x] The link to the presentation and the handout published on GitHub

**Syed Mohd Anas**  
Cologne, Germany  
Date: *[insert submission date]*





